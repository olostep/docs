---
sidebarTitle: 'Scrape'
title: Scrape
icon: file-lines
---

The Scrape endpoint allows to get the content from any publicly available web page. You can specify various params like the format in which you want the result to be returned (markdown, html, structured json, raw pdf, network calls), how much to wait before scraping or which actions to take before returning the content, etc. For a complete overview of the params see [here](/api-reference/scrapes/create)

## How to use the Scrape endpoint

In the example below we will see how to scrape `https://en.wikipedia.org/wiki/Alexander_the_Great` and get back the html and markdown from the url.

<CodeGroup>

```python scrape.py
import requests
import json

endpoint = "https://api.olostep.com/v1/scrapes"
payload = {
    "formats": [
        "html", 
        "markdown"
    ],
    "url_to_scrape": "https://en.wikipedia.org/wiki/Alexander_the_Great",
}
headers = {
    "Authorization": "Bearer <YOUR_API_KEY>",
    "Content-Type": "application/json"
}

# Make the request
response = requests.request("POST", endpoint, json=payload, headers=headers)
print(json.dumps(response.json(), indent=4))
```

</CodeGroup>

## Response Format

When you run the above code, you will receive a response like the following

```json
{
    "id": "scrape_6h89o8u1kt",
    "object": "scrape",
    "created": 1745673871,
    "metadata": {},
    "retrieve_id": "6h89o8u1kt",
    "url_to_scrape": "https://en.wikipedia.org/wiki/Alexander_the_Great",
    "result": {
        "html_content": "<html...",
        "markdown_content": "## Alexander the Great...",
        "text_content": null,
        "json_content": null,
        "screenshot_hosted_url": null,
        "html_hosted_url": "https://olostep-storage.s3.us-east-1.amazonaws.com/text_6h89o8u1kt.txt",
        "markdown_hosted_url": "https://olostep-storage.s3.us-east-1.amazonaws.com/markDown_6h89o8u1kt.txt",
        "json_hosted_url": null,
        "text_hosted_url": null,
        "network_calls": null,
        "links_on_page": [],
        "page_metadata": {
            "status_code": 200,
            "title": ""
        }
    }
}
```

## Conclusion

The scrape endpoint is useful when you need to extract html, markdown, text, raw pdf or structured data from a single website or page on demand. Here are a few practical applications for a Web Scraping Endpoint

### Content Analysis & Research
- **Competitive Analysis**: Extract product details, pricing, and features from competitor websites
- **Market Research**: Analyze landing pages, product descriptions, and customer testimonials
- **Academic Research**: Gather specific data from scientific publications or research portals
- **Legal Documentation**: Extract case studies, regulations, or legal precedents from official websites

### E-commerce & Retail
- **Dynamic Pricing Strategies**: Get real-time product pricing from competing stores
- **Product Information Management**: Extract detailed specifications and descriptions
- **Stock/Inventory Monitoring**: Check product availability at other retailers
- **Review Analysis**: Gather consumer feedback and sentiment for specific products

### Marketing & Content Creation
- **Content Curation**: Extract relevant articles and blog posts for newsletters
- **SEO Analysis**: Examine competitors' keyword usage, meta descriptions, and page structure
- **Lead Generation**: Extract contact information from business directories or company pages
- **Influencer Research**: Gather engagement metrics and content styles from influencer profiles
- **Personalised Social Media generation**: Create AI-powered social media marketing by analyzing customers websites 

### Data Applications
- **AI Training Data Collection**: Gather specific examples for machine learning models
- **Custom Knowledge Base Building**: Extract documentation or instructions from software sites
- **Historical Data Archives**: Preserve website content at specific points in time
- **Structured Data Extraction**: Transform web content into formatted datasets for analysis

### Monitoring & Alerts
- **Regulatory Compliance Monitoring**: Track changes to legal or regulatory websites
- **Crisis Management**: Monitor news sites for mentions of specific events or organizations
- **Event Tracking**: Extract details about upcoming events from venue or organizer websites
- **Service Status Monitoring**: Check service status pages for specific platforms or tools

### Publishing & Media
- **News Aggregation**: Extract breaking news from official sources
- **Media Monitoring**: Track specific topics across news sites
- **Content Verification**: Extract information to fact-check claims or statements
- **Multimedia Extraction**: Gather embedded videos, images, or audio for media libraries

### Financial Applications
- **Investment Research**: Extract financial statements or annual reports from company websites
- **Economic Indicators**: Gather economic data from government or financial institution websites
- **Cryptocurrency Data**: Extract real-time pricing and market cap information
- **Financial News Analysis**: Monitor financial news sites for specific market signals

### Technical Applications
- **API Documentation Extraction**: Gather technical documentation for reference
- **Integration Testing**: Extract website elements to verify third-party integrations
- **Accessibility Testing**: Analyze website structure for compliance with accessibility standards
- **Web Archive Creation**: Capture full website content for historical preservation

### Integration Scenarios
- **CRM Systems**: Enhance customer profiles with data from company websites or Linkedin
- **Content Management Systems**: Import relevant external content
- **Business Intelligence Tools**: Supplement internal data with external market information
- **Project Management Software**: Extract specifications or requirements from client websites
- **Custom Dashboards**: Display extracted data alongside internal metrics
