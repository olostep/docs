---
title: "Introduction"
description: "Introduction to Olostep's batch processing capabilities"
---

Batches allow you to process large numbers of URLs efficiently through our distributed architecture. Instead of making individual API calls, you can send up to 10,000 URLs in a single batch request.

## Features

- Process up to 10,000 URLs in a single batch
- Distributed parallel processing across multiple nodes
- Support for both HTML and Markdown content retrieval
- Real-time status tracking and progress monitoring
- Automatic retry mechanism for failed URLs
- Multiple parser support for specialized content extraction
- Country-specific node selection for optimal performance

## Basic Usage

```python
import requests

response = requests.post(
    "https://batches.olostep.com/batches",
    headers={
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
    },
    json={
        "items": [
            {
                "custom_id": "product_123",
                "url": "https://example.com/product-123"
            }
        ],
        "batch_parser": "none",
        "country": "RANDOM"
    }
)

batch_id = response.json()['id']
```

## Limitations

| **Limit**                  |                                         **Value** |
|----------------------------|---------------------------------------------------|
| Maximum URLs per batch     |                                           10,000  |
| Minimum URLs per batch     |                                               1   |
| URLs per node              |                                              20   |
| Check interval (normal)    |                                       72 seconds  |
| Check interval (fast)      |                                       20 seconds  |

## Process Flow

1. **Create a batch** with your URLs
2. URLs are distributed across available nodes
3. Content is processed in parallel
4. Results are stored securely
5. Automatic retries for failed URLs
6. Content available for retrieval

## Best Practices

- Group related URLs in the same batch
- Use meaningful `custom_id`s for easy tracking
- Specify `batch_parser` when dealing with specific websites
- Use `country` for region-specific content
- Monitor batch progress regularly
- Implement proper error handling

## Next Steps

- [Create your first batch](/api-reference/batch/create-batch)
- [Monitor batch status](/api-reference/batch/retrieve-batch)
- [Retrieve processed content](/api-reference/batch/retrieve-content)