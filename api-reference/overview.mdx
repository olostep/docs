---
title: 'Overview'
---

The API is structured around two main concepts: **Agents** and **Datasets**. For most use cases, you won't need the Datasets (defaultDatasetId) as they are used only to retrieve the content also later on.

## Agents

You can think of an agent as a "crawler" that is responsible for retrieving data from a specified URL and returning it into the desired format (HTML, Markdown or PDF).

You start an agent by sending a `GET` request to the `/olostep-p2p-incomingAPI` endpoint on the `agent.olostep.com` server. The response keeps hanging until:

1) the agent successfully finishes the scrape

2) there is an error (returned with a `5xx` or `4xx` status code)

3) or the scrape times out (you can specify the `timeout` in the request).

By using the `expandMarkdown` or `expandHTML` parameters you can directly retrieve the Markdown and HTML content (`markdown_content` and `html_content`) of the url you scraped. If you want to access this content again later on you can save the `defaultDatasetId` and use it to access the content at your convenience.

The `defaultDatasetId` basically is the unique identifier of the dataset that was created by the agent
## Datasets

Note: For most use cases you don't need to use the Datasets. They are only useful if you want to retrieve the content of the page you saved also later on and not just at the time of the scraping.

A dataset is a collection of data that was retrieved by an agent. Depending on your API tier, it remains available also for future reference (like a cached pointer to the page). You can access it by sending a `GET` request to the `/olostep-p2p-dataset-API` endpoint on the `dataset.olostep.com` server.
The response contains the following fields (depending on the configs sent to the agent):
`markdown_content` and `html_content`. If the requested page was a PDF, the `markdown_content` will contain the text extracted from the PDF.
